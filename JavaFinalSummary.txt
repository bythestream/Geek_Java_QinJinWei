Java3期毕业总结
1)JVM： 重点学习调优配置，垃圾回收，字节码技术
2)NIO：标准的IO基于字节流和字符流进行操作的，而NIO是基于通道（Channel）和缓冲区（Buffer）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。JavaNIO引入了选择器的概念，选择器用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个的线程可以监听多个数据通道。IO是面向流(字节流和字符流操作的，而NIO是面向缓冲区操作的。IO是阻塞性IO，而NIO是非阻塞性IO。IO不支持选择器，而NIO支持选择器
3) 并发编程：守护线程（Daemon）为用户线程（User）服务。JVM采用时间片轮转的方式调度线程，设置线程的优先级（但造成线程饥饿）。理解线程思索，学会使用Executor框架。
4)Spring 和 ORM 等框架。 Java ORM 常见的框架有 Hibernate JPA和MyBatis。MyBatis框架可应用于需求多变的互联网项目，如电商项目；Hibernate框架可应用于需求明确、业务固定的项目，如 OA 项目、ERP 项目等。。Hibernate框架是一个全表映射的框架。通常开发者只要定义好持久化对象到数据库表的映射关系，就可以通过Hibernate框架提供的方法完成持久层操作。开发者并不需要熟练地掌握 SQL 语句的编写，Hibernate 框架会根据编制的存储逻辑，自动生成对应的 SQL，并调用 JDBC 接口来执行，所以其开发效率会高于 MyBatis 框架。然而 Hibernate 框架自身也存在一些缺点，例如：•多表关联时，对SQL查询的支持较差；•更新数据时，需要发送所有字段；•不支持存储过程；•不能通过优化SQL来优化性能。这些问题导致其只适合在场景不太复杂且对性能要求不高的项目中使用。Sprint JPA 是在充分吸收了现有 Hibernate，TopLink，JDO 等 ORM 框架的基础上发展而来的，具有易于使用，伸缩性强等优点。
5)MySQL 数据库和 SQL. 分布式事务解决方案(XA, TCC, 消息事务). MySQL中主要的存储引擎(MyIASAM支持全文索引，查询效率比较高，缺点是不支持事务、使用表级锁,开销小，加锁快，不会出现死锁,访问效率比较低。行级锁开销大，加锁慢，有可能会出现死锁，不过因为锁定粒度最小，发生锁冲突的概率低，并发访问效率比较高。InnoDB使用行级锁。InnoDB在5.5版本后成为了Mysql的默认存储引).MySQL索引类型，索引实现（B+树实现，R-tree，Hash,FullText).MySQL调优(表结构和索引的优化,SQL语句进行优化的原则).
7)RPC 和微服务。RPC 主要用于公司内部的服务调用，性能消耗低，传输效率高，实现复杂。HTTP 主要用于对外的异构环境，浏览器接口调用，App 接口调用，第三方接口调用等。
RPC 使用场景(大型的网站，内部子系统较多、接口非常多的情况下适合使用 RPC)：长链接。不必每次通信都要像 HTTP 一样去 3 次握手，减少了网络开销。注册发布机制。RPC 框架一般都有注册中心，有丰富的监控管理;发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。安全性，没有暴露资源操作。微服务支持。就是最近流行的服务化架构、服务化治理，RPC 框架是一个强力的支撑。应用级的服务框架：阿里的 Dubbo/Dubbox、Google gRPC、Spring Boot/Spring Cloud。 远程通信协议：RMI、Socket、SOAP(HTTP XML)、REST(HTTP JSON)。 通信框架：MINA 和 Netty。
8) 分布式缓存。Redis是一个遵循BSD协议开源免费、基于内存Key-Value结构化存储的存储系统，在实际生产环境中可以将其作为数据库、缓存和消息中间件等提供配置服务器，消息代理和数据库。redis减少数据库的IO（输入输出）操作来降低服务器整体的压力。
9) 分布式消息队列。kafka的最小存储单元是分区，一个topic包含多个分区，kafka创建主题时，这些分区会被分配在多个服务器上，通常一个broker一台服务器;支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。RabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布订阅）、可靠性、安全。AMQP协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次. RocketMQ思路起源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。Pulsar 既可以像Kafka那样高速率的实时流处理，也支持标准的消息队列模式，比如多消费者、失效备援订阅和消息扇出（像rabbitMQ). Kafka 中的所有主题都是分区的，来增加吞吐量。通过分区，单个主题的处理速率可以得到大幅提升。但如果某些主题不需要太高的处理速率，那就不需要考虑分区了，以避免复杂的 API和管理方面的工作；Pulsar可以不分区。kafka在单台服务器上保存所有日志对宕机，拷贝，迁移都是一个挑战。Pulsar ledger 对日志进行分段，从而避免了拷贝大块的日志。它通过BookKeeper将日志分段分散到多台不同的服务器上。也就是说，日志并不是保存在单台服务器上，所以任何一台服务器都不会成为整个系统的瓶颈. Kafka每个 broker 都是有状态的，包含了分区的所有日志，如果一个 broker 宕机，并非任意一 broker 都可以接替它的工作。如果工作负载太高，也不能随意添加新的 broker 来分担。broker 之间必须进行状态同步。在 Pulsar 架构中，broker 是无状态的。但是完全无状态的系统是无法用来持久化消息的，所以 Pulsar 其实是在bookkeeper里维护在状态的。在 Pulsar 架构中，数据的分发和保存是相互独立的。broker 从生产者接收数据，然后将数据发送给消费者，因为 Pulsar 的broker是无状态的，所以如果工作负载很高，就可以直接添加新的 broker。

thanks!